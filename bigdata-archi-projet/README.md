# ğŸ“˜ Projet Big Data â€” Analyse du trafic dâ€™une application mobile

## 1. Contexte du projet

Ce projet est rÃ©alisÃ© dans le cadre du module **Open Data / Big Data & Intelligence Artificielle**.
Il a pour objectif de concevoir et de mettre en Å“uvre une **architecture Big Data** permettant de traiter un grand volume de donnÃ©es gÃ©nÃ©rÃ©es par une **application mobile**, en combinant :

* le **traitement en temps rÃ©el (streaming)**
* le **traitement diffÃ©rÃ© (batch)**

Les technologies utilisÃ©es sont **open source** et conformes Ã  celles vues en cours.

---

## 2. ThÃ¨me du projet

### ğŸ¯ Analyse Big Data du trafic dâ€™une application mobile

Une application mobile gÃ©nÃ¨re en continu des **Ã©vÃ©nements utilisateurs**, tels que :

* ouverture dâ€™Ã©crans,
* clics,
* appels API,
* rÃ©ponses serveur.

Ces Ã©vÃ©nements sont exploitÃ©s afin de **comprendre lâ€™usage de lâ€™application** et **Ã©valuer la performance des requÃªtes**.

---

## 3. Objectifs du projet

Les objectifs principaux sont :

* Mettre en place une **architecture Big Data complÃ¨te**
* Ingestion de donnÃ©es en **temps rÃ©el**
* Stockage distribuÃ© de donnÃ©es volumineuses
* Traitement batch pour lâ€™analyse historique
* Extraction dâ€™indicateurs mÃ©tiers simples

### Indicateurs analysÃ©s :

* Nombre dâ€™Ã©vÃ©nements par Ã©cran
* Nombre dâ€™Ã©vÃ©nements par type
* Temps de rÃ©ponse moyen par Ã©cran
* Identification des Ã©crans lents (> 0,6 s)

---

## 4. Architecture globale

Lâ€™architecture repose sur trois composants principaux :

* **Kafka** : ingestion des Ã©vÃ©nements en temps rÃ©el
* **HDFS** : stockage distribuÃ© des donnÃ©es (Data Lake)
* **MapReduce** : traitement batch et agrÃ©gation des donnÃ©es

### SchÃ©ma simplifiÃ© :

```
[ Application mobile ]
           |
           v
        Kafka
           |
           v
        HDFS
           |
           v
      MapReduce
           |
           v
     RÃ©sultats
```

Cette architecture correspond Ã  une **architecture de type Lambda**, combinant batch et streaming.

---

## 5. Description des technologies utilisÃ©es

### ğŸ”¹ Apache Kafka

Kafka permet de simuler lâ€™arrivÃ©e dâ€™Ã©vÃ©nements en temps rÃ©el gÃ©nÃ©rÃ©s par lâ€™application mobile.
Il est utilisÃ© pour le **stream processing**.

### ğŸ”¹ HDFS (Hadoop Distributed File System)

HDFS est utilisÃ© comme **Data Lake**, permettant de stocker un grand volume de donnÃ©es de maniÃ¨re distribuÃ©e, avec tolÃ©rance aux pannes.

### ğŸ”¹ MapReduce

MapReduce est utilisÃ© pour effectuer des **traitements batch** sur les donnÃ©es stockÃ©es dans HDFS, afin de calculer des statistiques et indicateurs globaux.

---

## 6. Organisation du projet

```
bigdata-archi-projet/
â”œâ”€ data/        â†’ DonnÃ©es et gÃ©nÃ©rateur dâ€™Ã©vÃ©nements
â”œâ”€ hdfs/        â†’ Scripts de gestion HDFS
â”œâ”€ kafka/       â†’ Producer et consumer Kafka
â”œâ”€ mapreduce/   â†’ Jobs MapReduce
â”œâ”€ scripts/     â†’ Scripts de dÃ©monstration
â”œâ”€ docker-compose.yml
â””â”€ README.md
```

---

## 7. Format des donnÃ©es

Chaque Ã©vÃ©nement mobile est reprÃ©sentÃ© sous la forme suivante :

```
DATE HEURE USER SCREEN EVENT_TYPE HTTP_CODE RESPONSE_TIME
```

Exemple :

```
2025-01-01 10:23 user42 HOME_SCREEN API_CALL 200 0.234
```

---

## 8. Lancement du projet (vue dâ€™ensemble)

### 1ï¸âƒ£ DÃ©marrer lâ€™environnement

```bash
docker-compose up -d
```

### 2ï¸âƒ£ Initialiser HDFS

```bash
bash hdfs/hdfs_init.sh
```

### 3ï¸âƒ£ Charger les donnÃ©es dans HDFS

```bash
bash hdfs/hdfs_put.sh
```

### 4ï¸âƒ£ Lancer un job MapReduce

```bash
bash mapreduce/job1_events_by_screen/run.sh
```

### 5ï¸âƒ£ Lancer le streaming Kafka

```bash
python kafka/producer.py
python kafka/consumer.py
```

---

## 9. RÃ©partition des tÃ¢ches (exemple)

* Membre 1 : Architecture & HDFS
* Membre 2 : MapReduce (batch processing)
* Membre 3 : Kafka (stream processing)
* Membre 4 : Documentation & prÃ©sentation

---

## 10. Conclusion

Ce projet illustre la mise en Å“uvre dâ€™une **architecture Big Data simple et fonctionnelle**, capable de gÃ©rer des donnÃ©es volumineuses et continues, tout en respectant les concepts fondamentaux du Big Data vus en cours.