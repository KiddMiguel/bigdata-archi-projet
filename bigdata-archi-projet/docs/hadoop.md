# ğŸ§  Câ€™est quoi Hadoop Streaming (trÃ¨s simplement)

ğŸ‘‰ **Hadoop Streaming est un mode dâ€™utilisation de MapReduce**
ğŸ‘‰ Il permet dâ€™utiliser **nâ€™importe quel langage** (Python, Bash, etc.)
ğŸ‘‰ au lieu dâ€™Ã©crire du **Java Hadoop compliquÃ©**

### Phrase simple Ã  retenir

> **Hadoop Streaming permet dâ€™exÃ©cuter des scripts (ex : Python) comme des jobs MapReduce.**

---

# âŒ Sans Hadoop Streaming (le monde compliquÃ©)

Si Hadoop Streaming nâ€™existait pas :

* Tu devrais Ã©crire :

  * un `Mapper` Java
  * un `Reducer` Java
* Compiler du Java
* GÃ©rer des classes Hadoop
* Beaucoup de code, trÃ¨s verbeux

âŒ **Pas adaptÃ© Ã  un projet pÃ©dagogique**
âŒ **Trop lourd pour ton objectif**

---

# âœ… Avec Hadoop Streaming (TON projet)

Avec Hadoop Streaming :

* Tu Ã©cris :

  * `mapper.py`
  * `reducer.py`
* Hadoop se charge de :

  * distribuer les donnÃ©es
  * lancer les scripts
  * parallÃ©liser le calcul
  * regrouper les rÃ©sultats

ğŸ‘‰ **Tu te concentres sur la logique mÃ©tier**, pas sur Hadoop interne.

---

# ğŸ¬ ScÃ©nario concret DANS TON PROJET

## ğŸ¯ Objectif mÃ©tier

> *Savoir combien de fois chaque Ã©cran de lâ€™application mobile est utilisÃ©.*

---

## 1ï¸âƒ£ Les donnÃ©es (dans HDFS)

Dans `/input/mobile_events_sample.txt` :

```
2025-01-01 08:00:05 user22 CHECKOUT CLICK 200 0.159
2025-01-01 08:00:06 user141 PRODUCT API_CALL 200 0.31
2025-01-01 08:00:15 user205 HOME API_CALL 404 0.104
```

ğŸ‘‰ Hadoop va lire **ce fichier ligne par ligne**

---

## 2ï¸âƒ£ Hadoop Streaming appelle ton **mapper.py**

Ton `mapper.py` fait Ã§a :

```python
print("CHECKOUT\t1")
print("PRODUCT\t1")
print("HOME\t1")
```

ğŸ‘‰ Il transforme les lignes brutes en **clÃ© â†’ valeur**

ğŸ§  **Le mapper prÃ©pare les donnÃ©es**, il ne calcule pas encore.

---

## 3ï¸âƒ£ Hadoop fait le travail â€œmagiqueâ€ (important)

âš ï¸ **Tu ne codes PAS Ã§a**, Hadoop sâ€™en charge :

* il regroupe automatiquement :

```
CHECKOUT â†’ [1, 1, 1, 1]
PRODUCT  â†’ [1, 1]
HOME     â†’ [1, 1, 1]
```

ğŸ‘‰ Cette Ã©tape sâ€™appelle le **shuffle & sort**

---

## 4ï¸âƒ£ Hadoop Streaming appelle ton **reducer.py**

Ton `reducer.py` reÃ§oit :

```
CHECKOUT    1
CHECKOUT    1
CHECKOUT    1
```

Il calcule :

```
CHECKOUT    3
```

ğŸ§  **Le reducer rÃ©sume**, **agrÃ¨ge**, **conclut**

---

## 5ï¸âƒ£ Hadoop Ã©crit le rÃ©sultat dans `/output`

Dans :

```
/output/job1_events_by_screen/part-00000
```

Tu obtiens :

```
HOME        1
PRODUCT     1
CHECKOUT    1
```

ğŸ‘‰ **Câ€™est de lâ€™information utile**, pas juste des logs.

---

# ğŸ” Pourquoi on appelle Ã§a â€œStreamingâ€ alors ?

âš ï¸ TrÃ¨s important :
**Hadoop Streaming â‰  Kafka streaming**

### Hadoop Streaming :

* â€œStreamingâ€ = *les donnÃ©es passent par stdin/stdout*
* Pas du temps rÃ©el
* Câ€™est du **batch**

ğŸ‘‰ Mauvais nom, mais historique.

---

### Kafka Streaming (TON Kafka) :

* Vrai temps rÃ©el
* Ã‰vÃ©nements instantanÃ©s

ğŸ‘‰ **Deux choses totalement diffÃ©rentes**

---

# ğŸ§© Pourquoi Hadoop Streaming est PARFAIT pour ton projet

| Besoin                      | Solution         |
| --------------------------- | ---------------- |
| Traiter beaucoup de donnÃ©es | Hadoop           |
| Pas Ã©crire du Java          | Hadoop Streaming |
| Utiliser Python             | Hadoop Streaming |
| Projet pÃ©dagogique          | Hadoop Streaming |

---

# ğŸ¤ Phrase parfaite Ã  dire au prof

> *Hadoop Streaming nous permet dâ€™exÃ©cuter des scripts Python comme des jobs MapReduce, sans avoir Ã  dÃ©velopper en Java, tout en bÃ©nÃ©ficiant du traitement distribuÃ© de Hadoop.*

ğŸ’¯ **Phrase clÃ©.**

---

# ğŸ§  RÃ©sumÃ© en 5 lignes (Ã  mÃ©moriser)

* Hadoop Streaming = **MapReduce en Python**
* Le mapper **transforme** les donnÃ©es
* Hadoop **regroupe** automatiquement
* Le reducer **agrÃ¨ge**
* Le rÃ©sultat est stockÃ© dans HDFS